{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "326506b6-6f60-4196-9d30-a9e8fb18a43e",
   "metadata": {},
   "source": [
    "# Model Training — Recycling Rate (%)\n",
    "\n",
    "Goal: Train a robust regressor with categorical-heavy data.\n",
    "- Recreate minimal FE so this notebook is standalone\n",
    "- Baselines (Dummy, RandomForest), then CatBoost (categorical-native)\n",
    "- Stratified holdout by target bins for stable evaluation\n",
    "- Save best model + metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0707c6-dfb2-4aa7-931a-131921b6e909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] using relative path\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(850, 4, 9, (680, 13), (170, 13))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setup\n",
    "import sys, os, warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "sys.path.insert(0, os.path.abspath(\"../src\"))\n",
    "\n",
    "from data.preprocess import load_data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# load RAW\n",
    "df = load_data()  # uses  preprocess.py logic (relative, abs, else URL)\n",
    "\n",
    "# minimal FE (safe to re-run)\n",
    "if \"Latitude\" not in df.columns:\n",
    "    latlon = df[\"Landfill Location (Lat, Long)\"].str.split(\",\", n=1, expand=True)\n",
    "    df[\"Latitude\"]  = latlon[0].astype(float)\n",
    "    df[\"Longitude\"] = latlon[1].str.strip().astype(float)\n",
    "\n",
    "for col in [\"Landfill Name\",\"Landfill Location (Lat, Long)\"]:\n",
    "    if col in df.columns:\n",
    "        df.drop(columns=col, inplace=True)\n",
    "\n",
    "# simple interaction that helped: Waste × Method\n",
    "if \"Waste_Method\" not in df.columns:\n",
    "    df[\"Waste_Method\"] = df[\"Waste Type\"] + \"|\" + df[\"Disposal Method\"]\n",
    "\n",
    "# optional density bin\n",
    "if \"Density_Bin\" not in df.columns:\n",
    "    try:\n",
    "        df[\"Density_Bin\"] = pd.qcut(df[\"Population Density (People/km²)\"], 4,\n",
    "                                    labels=[\"Low\",\"Mid-Low\",\"Mid-High\",\"High\"], duplicates=\"drop\")\n",
    "    except Exception:\n",
    "        df[\"Density_Bin\"] = pd.cut(df[\"Population Density (People/km²)\"], 4,\n",
    "                                   labels=[\"Low\",\"Mid-Low\",\"Mid-High\",\"High\"])\n",
    "\n",
    "target_col = \"Recycling Rate (%)\"\n",
    "\n",
    "# feature sets for sklearn (OneHot model)\n",
    "cat_cols = [c for c in [\"City/District\",\"Waste Type\",\"Disposal Method\",\"Density_Bin\"] if c in df.columns]\n",
    "num_cols = [c for c in df.columns if c not in cat_cols + [target_col, \"Waste_Method\"]]\n",
    "\n",
    "X = df[cat_cols + num_cols].copy()\n",
    "y = df[target_col].astype(float).copy()\n",
    "\n",
    "# stratified split by target bins (stabilizes holdout)\n",
    "from sklearn.model_selection import train_test_split\n",
    "y_bins = pd.qcut(y, q=10, duplicates=\"drop\").astype(str)\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y_bins)\n",
    "\n",
    "len(df), len(cat_cols), len(num_cols), X_tr.shape, X_te.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf6ea379-67e1-484b-8edb-a95f4d2c175b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'DUMMY_MAE': np.float64(13.916), 'DUMMY_RMSE': np.float64(16.119), 'DUMMY_R2': -0.0}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "num_pipe = Pipeline([(\"impute\", SimpleImputer(strategy=\"median\"))])\n",
    "cat_pipe = Pipeline([(\"impute\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "                     (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))])\n",
    "pre = ColumnTransformer([(\"num\", num_pipe, num_cols), (\"cat\", cat_pipe, cat_cols)])\n",
    "\n",
    "dummy = Pipeline([(\"pre\", pre), (\"model\", DummyRegressor(strategy=\"mean\"))])\n",
    "dummy.fit(X_tr, y_tr)\n",
    "pred_d = dummy.predict(X_te)\n",
    "\n",
    "print({\"DUMMY_MAE\": round(mean_absolute_error(y_te, pred_d),3),\n",
    "       \"DUMMY_RMSE\": round(mean_squared_error(y_te, pred_d, squared=False),3),\n",
    "       \"DUMMY_R2\": round(r2_score(y_te, pred_d),3)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5dd299b-378a-4297-a526-93f7387bdb77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MAE': np.float64(14.533), 'RMSE': np.float64(16.765), 'R2': -0.082}\n",
      "Saved: ../models/model_rf.pkl\n"
     ]
    }
   ],
   "source": [
    "import os, joblib\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=400, random_state=42, n_jobs=-1)\n",
    "pipe = Pipeline([(\"pre\", pre), (\"model\", rf)])\n",
    "pipe.fit(X_tr, y_tr)\n",
    "pred = pipe.predict(X_te)\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "rf_metrics = {\"MAE\": round(mean_absolute_error(y_te, pred),3),\n",
    "              \"RMSE\": round(mean_squared_error(y_te, pred, squared=False),3),\n",
    "              \"R2\": round(r2_score(y_te, pred),3)}\n",
    "print(rf_metrics)\n",
    "\n",
    "os.makedirs(\"../models\", exist_ok=True)\n",
    "joblib.dump(pipe, \"../models/model_rf.pkl\")\n",
    "print(\"Saved: ../models/model_rf.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68a996bf-e98d-4eb0-b68f-eca039bf70be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>cv_MAE</th>\n",
       "      <th>cv_RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>14.439324</td>\n",
       "      <td>16.802474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GBR</td>\n",
       "      <td>14.688593</td>\n",
       "      <td>17.219227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ExtraTrees</td>\n",
       "      <td>14.717835</td>\n",
       "      <td>17.314825</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          model     cv_MAE    cv_RMSE\n",
       "0  RandomForest  14.439324  16.802474\n",
       "2           GBR  14.688593  17.219227\n",
       "1    ExtraTrees  14.717835  17.314825"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.ensemble import ExtraTreesRegressor, GradientBoostingRegressor\n",
    "import pandas as pd\n",
    "\n",
    "def make_pipe(model): return Pipeline([(\"pre\", pre), (\"model\", model)])\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "models = {\n",
    "    \"RandomForest\": RandomForestRegressor(n_estimators=400, random_state=42, n_jobs=-1),\n",
    "    \"ExtraTrees\":   ExtraTreesRegressor(n_estimators=600, random_state=42, n_jobs=-1),\n",
    "    \"GBR\":          GradientBoostingRegressor(random_state=42)\n",
    "}\n",
    "rows = []\n",
    "for name, mdl in models.items():\n",
    "    p = make_pipe(mdl)\n",
    "    rmse = -cross_val_score(p, X, y, scoring=\"neg_root_mean_squared_error\", cv=kf, n_jobs=-1).mean()\n",
    "    mae  = -cross_val_score(p, X, y, scoring=\"neg_mean_absolute_error\", cv=kf, n_jobs=-1).mean()\n",
    "    rows.append([name, mae, rmse])\n",
    "\n",
    "cmp = pd.DataFrame(rows, columns=[\"model\",\"cv_MAE\",\"cv_RMSE\"]).sort_values(\"cv_RMSE\")\n",
    "cmp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7bd7c578-e43d-41d6-bdcb-9930d6daff94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Disposal Method</td>\n",
       "      <td>0.011379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Landfill Capacity (Tons)</td>\n",
       "      <td>0.000744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Year</td>\n",
       "      <td>-0.002786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>City/District</td>\n",
       "      <td>-0.004047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Population Density (People/km²)</td>\n",
       "      <td>-0.005229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Density_Bin</td>\n",
       "      <td>-0.006565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Cost of Waste Management (₹/Ton)</td>\n",
       "      <td>-0.006762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Waste Generated (Tons/Day)</td>\n",
       "      <td>-0.008042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Longitude</td>\n",
       "      <td>-0.012033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Latitude</td>\n",
       "      <td>-0.012631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Waste Type</td>\n",
       "      <td>-0.018454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Municipal Efficiency Score (1-10)</td>\n",
       "      <td>-0.018817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Awareness Campaigns Count</td>\n",
       "      <td>-0.029033</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              feature  importance\n",
       "2                     Disposal Method    0.011379\n",
       "9            Landfill Capacity (Tons)    0.000744\n",
       "10                               Year   -0.002786\n",
       "0                       City/District   -0.004047\n",
       "5     Population Density (People/km²)   -0.005229\n",
       "3                         Density_Bin   -0.006565\n",
       "7    Cost of Waste Management (₹/Ton)   -0.006762\n",
       "4          Waste Generated (Tons/Day)   -0.008042\n",
       "12                          Longitude   -0.012033\n",
       "11                           Latitude   -0.012631\n",
       "1                          Waste Type   -0.018454\n",
       "6   Municipal Efficiency Score (1-10)   -0.018817\n",
       "8           Awareness Campaigns Count   -0.029033"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "import pandas as pd\n",
    "\n",
    "orig_feat_names = list(X.columns)  # the exact columns given to the pipeline\n",
    "r = permutation_importance(pipe, X_te, y_te, n_repeats=10, random_state=42, n_jobs=-1)\n",
    "imp_df = pd.DataFrame({\"feature\": orig_feat_names, \"importance\": r.importances_mean}) \\\n",
    "           .sort_values(\"importance\", ascending=False).head(20)\n",
    "imp_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe46a45f-d04b-4ad3-aa3a-2b3c682e8b10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CB_MAE': np.float64(13.892), 'CB_RMSE': np.float64(16.089), 'CB_R2': 0.004}\n",
      "Saved: ../models/model_catboost.cbm\n"
     ]
    }
   ],
   "source": [
    "# If not installed in your venv: uncomment the next line, run once\n",
    "# %pip install catboost -q\n",
    "\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# CatBoost uses raw categoricals, so include the interaction explicitly\n",
    "cb_cat_cols = [c for c in [\"City/District\",\"Waste Type\",\"Disposal Method\",\"Density_Bin\",\"Waste_Method\"] if c in df.columns]\n",
    "cb_num_keep = [\"Waste Generated (Tons/Day)\",\"Population Density (People/km²)\",\"Municipal Efficiency Score (1-10)\",\n",
    "               \"Cost of Waste Management (₹/Ton)\",\"Awareness Campaigns Count\",\"Landfill Capacity (Tons)\",\"Year\"]\n",
    "cb_num_keep = [c for c in cb_num_keep if c in df.columns]\n",
    "\n",
    "X_cb = df[cb_cat_cols + cb_num_keep].copy()\n",
    "y_cb = df[target_col].astype(float).copy()\n",
    "\n",
    "# stratified holdout again (same idea)\n",
    "y_bins_cb = pd.qcut(y_cb, q=10, duplicates=\"drop\").astype(str)\n",
    "Xtr, Xte, ytr, yte = train_test_split(X_cb, y_cb, test_size=0.2, random_state=42, stratify=y_bins_cb)\n",
    "\n",
    "train_pool = Pool(Xtr, ytr, cat_features=cb_cat_cols)\n",
    "valid_pool = Pool(Xte, yte, cat_features=cb_cat_cols)\n",
    "\n",
    "cb = CatBoostRegressor(\n",
    "    iterations=2000, learning_rate=0.08, depth=6, l2_leaf_reg=5,\n",
    "    loss_function=\"RMSE\", eval_metric=\"RMSE\",\n",
    "    random_seed=42, od_type=\"Iter\", od_wait=120, verbose=False\n",
    ")\n",
    "cb.fit(train_pool, eval_set=valid_pool, verbose=False)\n",
    "\n",
    "pred_cb = cb.predict(valid_pool)\n",
    "cb_metrics = {\"CB_MAE\": round(mean_absolute_error(yte, pred_cb),3),\n",
    "              \"CB_RMSE\": round(mean_squared_error(yte, pred_cb, squared=False),3),\n",
    "              \"CB_R2\": round(r2_score(yte, pred_cb),3)}\n",
    "print(cb_metrics)\n",
    "\n",
    "import os\n",
    "os.makedirs(\"../models\", exist_ok=True)\n",
    "cb.save_model(\"../models/model_catboost.cbm\")\n",
    "print(\"Saved: ../models/model_catboost.cbm\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9db3b7e-de42-4548-b10e-d2bdcb1c7dec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>depth</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>l2_leaf_reg</th>\n",
       "      <th>bagging_temperature</th>\n",
       "      <th>cv_rmse</th>\n",
       "      <th>cv_sd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.064816</td>\n",
       "      <td>0.102490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>0.03</td>\n",
       "      <td>6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>16.064816</td>\n",
       "      <td>0.102490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>0.03</td>\n",
       "      <td>3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>16.080788</td>\n",
       "      <td>0.088043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>0.03</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.080788</td>\n",
       "      <td>0.088043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>0.06</td>\n",
       "      <td>6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>16.081617</td>\n",
       "      <td>0.098125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   depth  learning_rate  l2_leaf_reg  bagging_temperature    cv_rmse     cv_sd\n",
       "0      8           0.03            6                  0.0  16.064816  0.102490\n",
       "1      8           0.03            6                  0.5  16.064816  0.102490\n",
       "2      6           0.03            3                  0.5  16.080788  0.088043\n",
       "3      6           0.03            3                  0.0  16.080788  0.088043\n",
       "4      6           0.06            6                  0.5  16.081617  0.098125"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# use same X_cb / y_cb / cb_cat_cols / cb_num_keep as above\n",
    "cat_idx = [X_cb.columns.get_loc(c) for c in cb_cat_cols]\n",
    "\n",
    "# stratify labels must be plain labels (not Interval)\n",
    "y_bins_all = pd.qcut(y_cb, q=10, duplicates=\"drop\").astype(str)\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "grid = [\n",
    "    {\"depth\": d, \"learning_rate\": lr, \"l2_leaf_reg\": l2, \"bagging_temperature\": bt}\n",
    "    for d in [4,6,8]\n",
    "    for lr in [0.03, 0.06]\n",
    "    for l2 in [3, 6]\n",
    "    for bt in [0, 0.5]\n",
    "]\n",
    "\n",
    "def cv_rmse(params):\n",
    "    rmses = []\n",
    "    for tr_idx, va_idx in skf.split(X_cb, y_bins_all):\n",
    "        tr_pool = Pool(X_cb.iloc[tr_idx], y_cb.iloc[tr_idx], cat_features=cat_idx)\n",
    "        va_pool = Pool(X_cb.iloc[va_idx], y_cb.iloc[va_idx], cat_features=cat_idx)\n",
    "        m = CatBoostRegressor(\n",
    "            iterations=2000, od_type=\"Iter\", od_wait=120, random_seed=42,\n",
    "            loss_function=\"RMSE\", eval_metric=\"RMSE\", verbose=False,\n",
    "            depth=params[\"depth\"], learning_rate=params[\"learning_rate\"],\n",
    "            l2_leaf_reg=params[\"l2_leaf_reg\"], bagging_temperature=params[\"bagging_temperature\"]\n",
    "        )\n",
    "        m.fit(tr_pool, eval_set=va_pool, verbose=False)\n",
    "        p = m.predict(va_pool)\n",
    "        rmses.append(mean_squared_error(y_cb.iloc[va_idx], p, squared=False))\n",
    "    return float(np.mean(rmses)), float(np.std(rmses))\n",
    "\n",
    "rows = []\n",
    "for p in grid:\n",
    "    mean_rmse, sd_rmse = cv_rmse(p)\n",
    "    rows.append({**p, \"cv_rmse\": mean_rmse, \"cv_sd\": sd_rmse})\n",
    "\n",
    "res_df = pd.DataFrame(rows).sort_values(\"cv_rmse\").reset_index(drop=True)\n",
    "res_df.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98a467ee-4c7f-46c3-aa76-0e1fb4527faf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best (CV): {'depth': 8.0, 'learning_rate': 0.03, 'l2_leaf_reg': 6.0, 'bagging_temperature': 0.0, 'cv_rmse': 16.06481644403686, 'cv_sd': 0.10249034777362172}\n",
      "{'CB_tuned_holdout_MAE': np.float64(13.917), 'CB_tuned_holdout_RMSE': np.float64(16.117), 'CB_tuned_holdout_R2': 0.0}\n",
      "Saved: ../models/model_best_catboost.cbm and ../models/metrics.json\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import json, os\n",
    "\n",
    "best = res_df.iloc[0].to_dict()\n",
    "print(\"Best (CV):\", best)\n",
    "\n",
    "# stratified holdout (same as before)\n",
    "y_bins = pd.qcut(y_cb, q=10, duplicates=\"drop\").astype(str)\n",
    "Xtr, Xte, ytr, yte = train_test_split(X_cb, y_cb, test_size=0.2, random_state=42, stratify=y_bins)\n",
    "\n",
    "tr_pool = Pool(Xtr, ytr, cat_features=cat_idx)\n",
    "te_pool = Pool(Xte, yte, cat_features=cat_idx)\n",
    "\n",
    "best_cb = CatBoostRegressor(\n",
    "    iterations=2000, od_type=\"Iter\", od_wait=120, random_seed=42,\n",
    "    loss_function=\"RMSE\", eval_metric=\"RMSE\", verbose=False,\n",
    "    depth=int(best[\"depth\"]), learning_rate=float(best[\"learning_rate\"]),\n",
    "    l2_leaf_reg=float(best[\"l2_leaf_reg\"]), bagging_temperature=float(best[\"bagging_temperature\"])\n",
    ")\n",
    "best_cb.fit(tr_pool, eval_set=te_pool, verbose=False)\n",
    "\n",
    "pred = best_cb.predict(te_pool)\n",
    "mae  = mean_absolute_error(yte, pred)\n",
    "rmse = mean_squared_error(yte, pred, squared=False)\n",
    "r2   = r2_score(yte, pred)\n",
    "\n",
    "print({\"CB_tuned_holdout_MAE\": round(mae,3), \"CB_tuned_holdout_RMSE\": round(rmse,3), \"CB_tuned_holdout_R2\": round(r2,3)})\n",
    "\n",
    "os.makedirs(\"../models\", exist_ok=True)\n",
    "best_cb.save_model(\"../models/model_best_catboost.cbm\")\n",
    "with open(\"../models/metrics.json\",\"w\") as f:\n",
    "    json.dump({\"model\":\"catboost\",\"params\":best,\n",
    "               \"MAE\":float(mae),\"RMSE\":float(rmse),\"R2\":float(r2)}, f, indent=2)\n",
    "print(\"Saved: ../models/model_best_catboost.cbm and ../models/metrics.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb280d15-fcb4-462b-97e4-a204de1dbe4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Cost of Waste Management (₹/Ton)', np.float64(27.55757047542828)),\n",
       " ('Disposal Method', np.float64(26.16968675017754)),\n",
       " ('Density_Bin', np.float64(20.42021329794006)),\n",
       " ('Municipal Efficiency Score (1-10)', np.float64(14.974423150847173)),\n",
       " ('Population Density (People/km²)', np.float64(10.87810632560696)),\n",
       " ('City/District', np.float64(0.0)),\n",
       " ('Waste Type', np.float64(0.0)),\n",
       " ('Waste_Method', np.float64(0.0)),\n",
       " ('Waste Generated (Tons/Day)', np.float64(0.0)),\n",
       " ('Awareness Campaigns Count', np.float64(0.0)),\n",
       " ('Landfill Capacity (Tons)', np.float64(0.0)),\n",
       " ('Year', np.float64(0.0))]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp_vals = best_cb.get_feature_importance(tr_pool)\n",
    "feat_names = list(X_cb.columns)\n",
    "top = sorted(zip(feat_names, imp_vals), key=lambda x: x[1], reverse=True)[:15]\n",
    "top\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f1632b42-5951-461b-b40c-e07278c99591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CB_TE_holdout_MAE': np.float64(13.915), 'CB_TE_holdout_RMSE': np.float64(16.111), 'CB_TE_holdout_R2': 0.001}\n",
      "Saved: ../models/model_best_catboost_te.cbm and ../models/metrics_target_encoding.json\n"
     ]
    }
   ],
   "source": [
    "# --- K-fold target encoding (no leakage) + CatBoost ---\n",
    "import numpy as np, pandas as pd, os, json\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "\n",
    "target_col = \"Recycling Rate (%)\"\n",
    "\n",
    "# ensure interaction present\n",
    "if \"Waste_Method\" not in df.columns:\n",
    "    df[\"Waste_Method\"] = df[\"Waste Type\"] + \"|\" + df[\"Disposal Method\"]\n",
    "\n",
    "# categoricals kept raw for CatBoost\n",
    "cat_cols_cb = [c for c in [\"City/District\",\"Waste Type\",\"Disposal Method\",\"Density_Bin\",\"Waste_Method\"] if c in df.columns]\n",
    "\n",
    "# core numerics (keep it simple)\n",
    "num_keep = [\n",
    "    \"Waste Generated (Tons/Day)\",\"Population Density (People/km²)\",\"Municipal Efficiency Score (1-10)\",\n",
    "    \"Cost of Waste Management (₹/Ton)\",\"Awareness Campaigns Count\",\"Landfill Capacity (Tons)\",\"Year\"\n",
    "]\n",
    "num_keep = [c for c in num_keep if c in df.columns]\n",
    "\n",
    "X_all = df[cat_cols_cb + num_keep].copy()\n",
    "y_all = df[target_col].astype(float).copy()\n",
    "\n",
    "# stratified split on target (stable holdout)\n",
    "y_bins = pd.qcut(y_all, q=10, duplicates=\"drop\").astype(str)\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(X_all, y_all, test_size=0.2, random_state=42, stratify=y_bins)\n",
    "\n",
    "# ---- leakage-safe K-fold target encoding on TRAIN only ----\n",
    "enc_cols = [c for c in [\"City/District\",\"Waste Type\",\"Disposal Method\",\"Waste_Method\"] if c in X_tr.columns]\n",
    "\n",
    "def kfold_target_encode(X_train, y_train, X_valid, col, n_splits=5, noise=0.01):\n",
    "    oof = pd.Series(index=X_train.index, dtype=float)\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    for tr_idx, va_idx in kf.split(X_train):\n",
    "        tr_ids = X_train.iloc[tr_idx].index\n",
    "        va_ids = X_train.iloc[va_idx].index\n",
    "        means = y_train.loc[tr_ids].groupby(X_train.loc[tr_ids, col]).mean()\n",
    "        oof.loc[va_ids] = X_train.loc[va_ids, col].map(means)\n",
    "    global_mean = y_train.mean()\n",
    "    oof = oof.fillna(global_mean)\n",
    "    if noise and noise > 0:\n",
    "        oof = oof * (1 + noise*np.random.randn(len(oof)))\n",
    "    mapping = y_train.groupby(X_train[col]).mean()\n",
    "    te_valid = X_valid[col].map(mapping).fillna(global_mean)\n",
    "    return oof.values, te_valid.values\n",
    "\n",
    "Xtr = X_tr.copy(); Xte = X_te.copy()\n",
    "te_feature_names = []\n",
    "for c in enc_cols:\n",
    "    tr_vals, te_vals = kfold_target_encode(Xtr, y_tr, Xte, c, n_splits=5, noise=0.01)\n",
    "    newc = f\"TE_{c.replace('/','_').replace(' ','_')}\"\n",
    "    Xtr[newc] = tr_vals\n",
    "    Xte[newc] = te_vals\n",
    "    te_feature_names.append(newc)\n",
    "\n",
    "# cat feature indices (positions of raw categoricals in current dataframe)\n",
    "cat_idx = [Xtr.columns.get_loc(c) for c in cat_cols_cb]\n",
    "\n",
    "# --- CatBoost (use tuned params found earlier) ---\n",
    "best_params = dict(depth=8, learning_rate=0.03, l2_leaf_reg=6, bagging_temperature=0.5)\n",
    "cb_te = CatBoostRegressor(\n",
    "    iterations=2000, od_type=\"Iter\", od_wait=120, random_seed=42,\n",
    "    loss_function=\"RMSE\", eval_metric=\"RMSE\", verbose=False, **best_params\n",
    ")\n",
    "\n",
    "train_pool = Pool(Xtr, y_tr, cat_features=cat_idx)\n",
    "test_pool  = Pool(Xte, y_te, cat_features=cat_idx)\n",
    "\n",
    "cb_te.fit(train_pool, eval_set=test_pool, verbose=False)\n",
    "pred = cb_te.predict(test_pool)\n",
    "\n",
    "mae  = mean_absolute_error(y_te, pred)\n",
    "rmse = mean_squared_error(y_te, pred, squared=False)\n",
    "r2   = r2_score(y_te, pred)\n",
    "\n",
    "print({\"CB_TE_holdout_MAE\": round(mae,3), \"CB_TE_holdout_RMSE\": round(rmse,3), \"CB_TE_holdout_R2\": round(r2,3)})\n",
    "\n",
    "# save artifacts\n",
    "os.makedirs(\"../models\", exist_ok=True)\n",
    "cb_te.save_model(\"../models/model_best_catboost_te.cbm\")\n",
    "with open(\"../models/metrics_target_encoding.json\",\"w\") as f:\n",
    "    json.dump({\"model\":\"catboost_te\",\"params\":best_params,\n",
    "               \"MAE\":float(mae),\"RMSE\":float(rmse),\"R2\":float(r2),\n",
    "               \"te_features\": te_feature_names}, f, indent=2)\n",
    "print(\"Saved: ../models/model_best_catboost_te.cbm and ../models/metrics_target_encoding.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ee0574-ff26-4bc1-92fb-708aa64f6c89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b5667e-c5e2-487b-8a65-35916402a12a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad2f7b4-d871-4078-8cec-85573095570c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d99056b-9d46-4a3e-837b-d35e1c8a2f02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79a92a7-b12b-4129-9d63-1334c8b90652",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3214bc-89ff-46a0-a8ab-3356ad1529c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd36bc8e-d833-41c1-a440-aae9dd0f7096",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75dd6d3d-2bbc-4857-8eff-7dd3047397a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d4936a-020d-4b97-86e9-c110a94bd30f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05386e14-8305-4240-adc0-e348d2c642cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8f3f16-2316-4eff-bd8d-32df111b9f8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616cfba2-4443-43b2-9058-6df5c635365c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
